# VizWiz-VQA
Visual Question Answering is a machine comprehension challenge wherein, provided a natural language question about an image, the system autonomously infers a natural language answer for the posed question.

VizWiz VQA dataset originates from images and questions compiled by members of the visually impaired community. It comes from a natural visual question answering setting where blind people take images and record a question about the image using a mobile application.

---

Prerequisites can be downloaded from ```tools/download_script.sh```

Training the model:
```
python main.py
```
